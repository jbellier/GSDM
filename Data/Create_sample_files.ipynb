{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date, chartostring\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import ma\n",
    "from numba import njit\n",
    "from numpy.random import lognormal, randint\n",
    "from scipy import ndimage\n",
    "from scipy.stats import gamma, rankdata\n",
    "from scipy.optimize import minimize, minimize_scalar\n",
    "import math\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "exec(open(\"/users/jbellier/Documents/Tools/Functions_dates.py\").read())\n",
    "exec(open(\"/users/jbellier/Documents/Tools/Functions_plots.py\").read())\n",
    "exec(open(\"/users/jbellier/Documents/Tools/Function_constrNMPy.py\").read())\n",
    "exec(open(\"/users/jbellier/Documents/Tools/Functions_circularData.py\").read())\n",
    "exec(open(\"/users/jbellier/Documents/GitHub/GSDM/Functions/Various_functions.py\").read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small sample of 10 coarse-scale and fine-scale fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_to_select = range(46,86)\n",
    "lb_lat, ub_lat, lb_lon, ub_lon = 31.7, 45.5, -124.8, -113.2\n",
    "\n",
    "## Fine-scale analyses:\n",
    "ncfile = '/users/jbellier/Documents/Data/NLDAS/NLDAS-California_20100101_to_20171231_precipOnly_6h_accumulation.nc'\n",
    "nc = Dataset(ncfile)\n",
    "lat_fine = nc.variables['latitude'][:]\n",
    "lon_fine = nc.variables['longitude'][:]\n",
    "yyyymmddhh_end6h = nc.variables['yyyymmddhh_valid'][dates_to_select]\n",
    "time_end6h = nc.variables['time'][dates_to_select]\n",
    "latRes_fine = np.diff(lat_fine)[0]\n",
    "lonRes_fine = np.diff(lon_fine)[0]\n",
    "id_lat_fine = np.logical_and(lat_fine >= lb_lat, lat_fine <= ub_lat)\n",
    "id_lon_fine = np.logical_and(lon_fine >= lb_lon, lon_fine <= ub_lon)\n",
    "lat_fine = lat_fine[id_lat_fine]\n",
    "lon_fine = lon_fine[id_lon_fine]\n",
    "N_fineFields = nc.variables['apcp_anal'][:][dates_to_select,:,:][:,id_lat_fine,:][:,:,id_lon_fine]\n",
    "nc.close()\n",
    "\n",
    "N, nya, nxa = N_fineFields.shape\n",
    "\n",
    "## Load the mask from the California project:\n",
    "ncfile = '/users/jbellier/Documents/Project_California/downscaled_fields/1stage/E40oS20/downscaled_fields_201610_000_to_003.nc'\n",
    "nc = Dataset(ncfile)\n",
    "mask_fine = nc.variables['S1_fields'][0,0,:,:].mask\n",
    "mask_fine = ma.array(np.zeros((nya,nxa)), mask=True)\n",
    "pos_lat = fun_matchIndex(lat_fine, nc.variables['latitude_fine'][:])\n",
    "pos_lon = fun_matchIndex(lon_fine, nc.variables['longitude_fine'][:])\n",
    "mask_fine[pos_lat[pos_lat.mask==False,None],\n",
    "          pos_lon[None,pos_lon.mask==False]] = nc.variables['S1_fields'][0,0,:,:].mask[pos_lat.mask==False,:][:,pos_lon.mask==False]\n",
    "nc.close()\n",
    "\n",
    "N_fineFields.mask = mask_fine[None,:,:]\n",
    "\n",
    "\n",
    "lat_fine = coord_equallySpaced(lat_fine)\n",
    "lon_fine = coord_equallySpaced(lon_fine)\n",
    "\n",
    "\n",
    "\n",
    "## Coarse-scale grid:\n",
    "ncfile = '/users/jbellier/Documents/Data/NLDAS/NLDAS-California_20100101_to_20171231_precipOnly_6h_accum_aggregated_to_GEFS_T254.nc'\n",
    "nc = Dataset(ncfile)\n",
    "lat_coarse = coord_equallySpaced(nc.variables['latitude_coarse'][:])\n",
    "lon_coarse = coord_equallySpaced(nc.variables['longitude_coarse'][:])\n",
    "latRes_coarse = np.diff(lat_coarse)[0]\n",
    "lonRes_coarse = np.diff(lon_coarse)[0]\n",
    "id_lat_coarse = np.logical_and(lat_coarse >= lb_lat, lat_coarse <= ub_lat)\n",
    "id_lon_coarse = np.logical_and(lon_coarse >= lb_lon, lon_coarse <= ub_lon)\n",
    "lat_coarse = lat_coarse[id_lat_coarse]\n",
    "lon_coarse = lon_coarse[id_lon_coarse]\n",
    "# N_coarseFields = nc.variables['apcp_anal'][:][dates_to_select,:,:]\n",
    "# assert np.all(yyyymmddhh_end6h == nc.variables['yyyymmddhh_valid'][dates_to_select])\n",
    "nc.close()\n",
    "\n",
    "nyc, nxc = lat_coarse.size, lon_coarse.size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb_lat, ub_lat, lb_lon, ub_lon = np.min(lat_fine), np.max(lat_fine), np.min(lon_fine), np.max(lon_fine)\n",
    "name_area = 'California_Nevada'\n",
    "\n",
    "list_namePred = ['WindSpeed','WindDir','WindSpeed','WindDir','MUCAPE','WindShearSpeed','LI']\n",
    "list_level_or_layer = [600,600,700,700,'None','sfc-700hPa','None']\n",
    "nb_diffPred = len(list_namePred)\n",
    "\n",
    "## Load the meteorological predictor original grid (ERA5):\n",
    "#---------------------------------------------\n",
    "# WARNING: lats are here in decreasing order!\n",
    "nc = Dataset('/users/jbellier/Documents/Data/ERA5/files/Orography/Orography.nc')\n",
    "lons_pred = nc.variables['longitude'][:]\n",
    "lats_pred = nc.variables['latitude'][:]\n",
    "res_pred = np.unique(np.diff(lons_pred))[0]\n",
    "id_lons_pred = np.logical_and(lons_pred >= lb_lon-res_pred, lons_pred <= ub_lon+res_pred)    # These will be used\n",
    "id_lats_pred = np.logical_and(lats_pred >= lb_lat-res_pred, lats_pred <= ub_lat+res_pred)    # when loading the netcdf\n",
    "lons_pred = lons_pred[id_lons_pred]\n",
    "lats_pred = np.flip(lats_pred[id_lats_pred])     # we flip to get back to latitude going in increasing order\n",
    "nc.close()\n",
    "\n",
    "nyp, nxp = len(lats_pred), len(lons_pred)\n",
    "\n",
    "Pred_originRes = ma.array(np.zeros((3,nb_diffPred,N,nyp,nxp), dtype='float64'), mask=True)\n",
    "\n",
    "\n",
    "\n",
    "## Note: ERA5 is at 6h time step only. But since here we consider TempResol_NLDAS = 6h, we load the predictor data at the beginning and end of the 6h period, and we keep the average of the two.\n",
    "##   (If TempResol_NLDAS = 3h, we would also take the average of the 6h period, for the two 3h period spanning the 6h period (means that two 3h periods will have the same predictor values).         \n",
    "\n",
    "## Vector of the beginning of the 6h period:\n",
    "yyyymmddhh_beg6h = np.zeros(N, dtype='int64')\n",
    "for n in range(N):\n",
    "    yyyymmddhh_beg6h[n] = date_to_yyyymmddhh(datetime(yyyy(yyyymmddhh_end6h[n]), mm(yyyymmddhh_end6h[n]), dd(yyyymmddhh_end6h[n]), hh(yyyymmddhh_end6h[n])) - timedelta(hours=6)) \n",
    "\n",
    "## yyyymmddhh_beg6h[0] might be in the previous year (occurs in Jan), so we replace by yyyymmddhh_end6h[0]:\n",
    "if yyyy(yyyymmddhh_beg6h[0]) !=  yyyy(yyyymmddhh_beg6h[1]):\n",
    "    yyyymmddhh_beg6h[0] = yyyymmddhh_end6h[0]\n",
    "## Similarly, yyyymmddhh_end6h[-1] might be in the next year (occurs in Dec), so we replace by yyyymmddhh_beg6h[-1]:\n",
    "if yyyy(yyyymmddhh_end6h[-1]) !=  yyyy(yyyymmddhh_end6h[-2]):\n",
    "    yyyymmddhh_end6h[-1] = yyyymmddhh_beg6h[-1]\n",
    "\n",
    "\n",
    "diffyears = np.unique(yyyy(np.append(yyyymmddhh_beg6h, yyyymmddhh_end6h)))\n",
    "\n",
    "\n",
    "\n",
    "for year in diffyears:\n",
    "\n",
    "    try:\n",
    "        ncfile  = '/users/jbellier/Documents/Data/ERA5/Predictors/Predictors_'+str(year)+'_'+name_area+'.nc'\n",
    "        nc = Dataset(ncfile)\n",
    "\n",
    "        ## Indices for the instantaneous values at the beginning (B) and end (E) of the 6h periods:\n",
    "        idB = fun_matchIndex(yyyymmddhh_beg6h, nc.variables['yyyymmddhh_valid'][:])\n",
    "        idE = fun_matchIndex(yyyymmddhh_end6h, nc.variables['yyyymmddhh_valid'][:])\n",
    "\n",
    "        idLat = fun_matchIndex(lats_pred, nc.variables['lat'][:])\n",
    "        idLon = fun_matchIndex(lons_pred, nc.variables['lon'][:])\n",
    "\n",
    "        for p in range(nb_diffPred):\n",
    "\n",
    "            namePred = list_namePred[p]\n",
    "            level_or_layer = list_level_or_layer[p]\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "                if level_or_layer == 'None':\n",
    "                    grid_B = nc.variables[namePred] [idB.mask==False,:,:][:,idLat.mask==False,:][:,:,idLon.mask==False]\n",
    "                    grid_E = nc.variables[namePred] [idE.mask==False,:,:][:,idLat.mask==False,:][:,:,idLon.mask==False]\n",
    "\n",
    "                else:\n",
    "                    if nc.variables[namePred].dimensions[1] == 'level':\n",
    "                        level_or_layer_to_load = np.where(nc.variables['level'][:] == np.int(level_or_layer))[0][0]\n",
    "                    elif nc.variables[namePred].dimensions[1] == 'layer':\n",
    "                        level_or_layer_to_load = np.where(chartostring(nc.variables['layer'][:]) == level_or_layer)[0][0]\n",
    "\n",
    "                    grid_B = nc.variables[namePred] [idB.mask==False,level_or_layer_to_load,:,:][:,idLat.mask==False,:][:,:,idLon.mask==False]\n",
    "                    grid_E = nc.variables[namePred] [idE.mask==False,level_or_layer_to_load,:,:][:,idLat.mask==False,:][:,:,idLon.mask==False]\n",
    "\n",
    "            Pred_originRes[0,p,:,:,:][idB[idB.mask==False,None,None],\n",
    "                                      idLat[None,idLat.mask==False,None],\n",
    "                                      idLon[None,None,idLon.mask==False]] = grid_B\n",
    "            Pred_originRes[1,p,:,:,:][idE[idE.mask==False,None,None],\n",
    "                                      idLat[None,idLat.mask==False,None],\n",
    "                                      idLon[None,None,idLon.mask==False]] = grid_E    \n",
    "        nc.close()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        warnings.warn(\"Tried to load '\"+ncfile+\"' but file not found.\")\n",
    "\n",
    "## Temporal averaging between the values at the beginning and end of the period:\n",
    "for p in range(nb_diffPred):\n",
    "    namePred = list_namePred[p]\n",
    "    level_or_layer = list_level_or_layer[p]\n",
    "    if 'Dir' in namePred:    # This predictor is a direction, so we need to perform a circular mean\n",
    "        Pred_originRes[2,p,:,:,:] = np.rad2deg(circular_mean_element_wise(np.deg2rad(Pred_originRes[0,p,:,:,:]), np.deg2rad(Pred_originRes[1,p,:,:,:])))\n",
    "    else:                    # \"Standard\" predictor, so we perform a regular mean\n",
    "        Pred_originRes[2,p,:,:,:] = 1/2 * (Pred_originRes[0,p,:,:,:] + Pred_originRes[1,p,:,:,:])\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "## Bilinearly interpolated to the coarse-scale:\n",
    "def iterpdata(lowres,mlats,mlons,lats,lons):\n",
    "    #  bivariate interpolation\n",
    "    idata = RectBivariateSpline(mlats,mlons,lowres,kx=1,ky=1,s=0)\n",
    "    hires = idata.__call__(lats,lons,grid=True)\n",
    "    return hires\n",
    "\n",
    "Pred_coarseRes = ma.array(np.zeros((nb_diffPred,N,nyc,nxc), dtype='float64'), mask=True)\n",
    "for p in range(nb_diffPred):\n",
    "    for n in range(N):\n",
    "        Pred_coarseRes[p,n,:,:] = iterpdata(Pred_originRes[2,p,n,:,:], lats_pred,  lons_pred, lat_coarse, lon_coarse)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = '/users/jbellier/Documents/GitHub/GSDM/Data/sample_data.nc'\n",
    "\n",
    "nc = Dataset(outfilename,'w',format='NETCDF4_CLASSIC')\n",
    "\n",
    "Dlat_fine_nc = nc.createDimension('lat_fine',nya)\n",
    "Dlon_fine_nc = nc.createDimension('lon_fine',nxa)\n",
    "Dlat_coarse_nc = nc.createDimension('lat_coarse',nyc)\n",
    "Dlon_coarse_nc = nc.createDimension('lon_coarse',nxc)\n",
    "Ddays = nc.createDimension('time',N)\n",
    "\n",
    "latitude_fine_nc = nc.createVariable('lat_fine','f8',('lat_fine',))\n",
    "latitude_fine_nc.long_name = 'latitude fine-scale fields'\n",
    "latitude_fine_nc.units = 'degrees_north'\n",
    "\n",
    "longitude_fine_nc = nc.createVariable('lon_fine','f8',('lon_fine',))\n",
    "longitude_fine_nc.long_name = 'longitude fine-scale fields'\n",
    "longitude_fine_nc.units = \"degrees_east\"    \n",
    "\n",
    "latitude_coarse_nc = nc.createVariable('lat_coarse','f8',('lat_coarse',))\n",
    "latitude_coarse_nc.long_name = 'latitude coarse-scale fields'\n",
    "latitude_coarse_nc.units = 'degrees_north'\n",
    "\n",
    "longitude_coarse_nc = nc.createVariable('lon_coarse','f8',('lon_coarse',))\n",
    "longitude_coarse_nc.long_name = 'longitude coarse-scale fields'\n",
    "longitude_coarse_nc.units = \"degrees_east\"    \n",
    "\n",
    "yyyymmddhh_end6h_nc = nc.createVariable('yyyymmddhh_end6h','i4',('time',))\n",
    "yyyymmddhh_end6h_nc.long_name = 'Date/time (yyyymmddhh format, in UTC) of the end of the 6h averaging period'\n",
    "\n",
    "time_end6h_nc = nc.createVariable('time','i4',('time',))\n",
    "time_end6h_nc.long_name = 'Date/time (in UTC) of the end of the 6h averaging period'\n",
    "time_end6h_nc.units = \"hours since 1900-01-01 00:00:00\"\n",
    "\n",
    "fine_fields_nc = nc.createVariable('fine_fields','f8',('time','lat_fine','lon_fine',), zlib=True)\n",
    "fine_fields_nc.long_name = 'Analysis fields'\n",
    "fine_fields_nc.units = \"mm\"\n",
    "fine_fields_nc.valid_range = [0,200]\n",
    "fine_fields_nc.missing_value = -999\n",
    "\n",
    "# coarse_fields_nc = nc.createVariable('coarse_fields','f8',('time','lat_coarse','lon_coarse',), zlib=True)\n",
    "# coarse_fields_nc.long_name = 'Analysis fields aggregated to the coarse-scale'\n",
    "# coarse_fields_nc.units = \"mm\"\n",
    "# coarse_fields_nc.valid_range = [0,200]\n",
    "# coarse_fields_nc.missing_value = -999\n",
    "\n",
    "windSpeed_600_nc = nc.createVariable('windSpeed_600','f8',('time','lat_coarse','lon_coarse',), zlib=True)\n",
    "windSpeed_600_nc.long_name = 'Wind speed (ground-relative) at 600 hPa'\n",
    "windSpeed_600_nc.units = \"m s**1\"\n",
    "windSpeed_600_nc.valid_range = [0,500]\n",
    "windSpeed_600_nc.missing_value = -9999\n",
    "\n",
    "windDir_600_nc = nc.createVariable('windDir_600','f8',('time','lat_coarse','lon_coarse',), zlib=True)\n",
    "windDir_600_nc.long_name = 'Wind direction at 600 hPa. 0 deg means East'\n",
    "windDir_600_nc.units = \"degree\"\n",
    "windDir_600_nc.valid_range = [-180,180]\n",
    "windDir_600_nc.missing_value = -9999\n",
    "\n",
    "windSpeed_700_nc = nc.createVariable('windSpeed_700','f8',('time','lat_coarse','lon_coarse',), zlib=True)\n",
    "windSpeed_700_nc.long_name = 'Wind speed (ground-relative) at 700 hPa'\n",
    "windSpeed_700_nc.units = \"m s**1\"\n",
    "windSpeed_700_nc.valid_range = [0,500]\n",
    "windSpeed_700_nc.missing_value = -9999\n",
    "\n",
    "windDir_700_nc = nc.createVariable('windDir_700','f8',('time','lat_coarse','lon_coarse',), zlib=True)\n",
    "windDir_700_nc.long_name = 'Wind direction at 700 hPa. 0 deg means East'\n",
    "windDir_700_nc.units = \"degree\"\n",
    "windDir_700_nc.valid_range = [-180,180]\n",
    "windDir_700_nc.missing_value = -9999\n",
    "\n",
    "CAPE_nc = nc.createVariable('CAPE','f8',('time','lat_coarse','lon_coarse',), zlib=True)\n",
    "CAPE_nc.long_name = 'Convective Available Potential Energy (most unstable CAPE in the lowest 350hPa, as in ERA5)'\n",
    "CAPE_nc.units = \"J kg**-1\"\n",
    "CAPE_nc.valid_range = [0,99999]\n",
    "CAPE_nc.missing_value = -9999\n",
    "\n",
    "WindShearSpeed_nc = nc.createVariable('WindShearSpeed_sfc_700','f8',('time','lat_coarse','lon_coarse',), zlib=True)\n",
    "WindShearSpeed_nc.long_name = 'Vertical wind shear in speed, between the surface and the 700 hPa level'\n",
    "WindShearSpeed_nc.units = \"m s**11\"\n",
    "WindShearSpeed_nc.valid_range = [0,500]\n",
    "WindShearSpeed_nc.missing_value = -9999\n",
    "\n",
    "LI_nc = nc.createVariable('LI','f8',('time','lat_coarse','lon_coarse',), zlib=True)\n",
    "LI_nc.long_name = 'Lifted Index'\n",
    "LI_nc.units = \"Degree Celsius\"\n",
    "LI_nc.valid_range = [-100,100]\n",
    "LI_nc.missing_value = -9999\n",
    "\n",
    "latitude_fine_nc[:] = lat_fine\n",
    "longitude_fine_nc[:] = lon_fine\n",
    "latitude_coarse_nc[:] = lat_coarse\n",
    "longitude_coarse_nc[:] = lon_coarse\n",
    "yyyymmddhh_end6h_nc[:] = yyyymmddhh_end6h\n",
    "time_end6h_nc[:] = time_end6h\n",
    "fine_fields_nc[:,:,:] = N_fineFields\n",
    "# coarse_fields_nc[:,:,:] = N_coarseFields\n",
    "\n",
    "\n",
    "windSpeed_600_nc[:,:,:] = Pred_coarseRes[0,:,:,:]\n",
    "windDir_600_nc[:,:,:] = Pred_coarseRes[1,:,:,:]\n",
    "windSpeed_700_nc[:,:,:] = Pred_coarseRes[2,:,:,:]\n",
    "windDir_700_nc[:,:,:] = Pred_coarseRes[3,:,:,:]\n",
    "CAPE_nc[:,:,:] = Pred_coarseRes[4,:,:,:]\n",
    "WindShearSpeed_nc[:,:,:] = Pred_coarseRes[5,:,:,:]\n",
    "LI_nc[:,:,:] = Pred_coarseRes[6,:,:,:]\n",
    "\n",
    "## Attributes of the NetCDF:\n",
    "nc.stream = \"s4\" # ????\n",
    "nc.title = 'Sample fine and coarse scale fields over California'\n",
    "nc.Conventions = \"CF-1.0\"  # ????\n",
    "nc.history = \"Created ~Mar 2021 by Joseph Bellier\" \n",
    "nc.institution = \"NOAA/ESRL Physical Sciences Laboratory\"\n",
    "nc.platform = \"Model\" \n",
    "nc.references = \"None\" \n",
    "\n",
    "nc.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
